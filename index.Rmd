--- 
title       : Text Anticipation
subtitle    : A Modest Effort in Text Prediction
author      : J.E. Turcotte
job         : 
framework   : io2012   
highlighter : highlight.js 
hitheme     : tomorrow
widgets     : []           
mode        : selfcontained 
knit        : slidify::knit2slides
--- 

## A Simple Application

* With this, I present a simple text prediction application
  * found at https://jeturcotte.shinyapps.io/TextAnticipation/
* The idea behind this application is to parse words up to the point where text has left off, and offer the most likely word to follow
* Its use is simple enough; Begin by typing and, if you like, pause long enough for the application to guess
* It will offer the most likely next word and even let you click on that word to append it to the sentence
  * given that many applications offer more than one possibility, I also include what those might be
* The result can be quite hilarious, actually, if you start it off and just let the predictive model jabber away

--- 

## Cleaning up the Original Corpus

* For this project, a modestly large corpus was provided -- Blogs, News Articles and a large slew of Tweets
* These were broken down into roughly 8.1 million individual sentences
* These had several passes of repair made... 
  * Numbers and Punctuation and Twitter handles were removed
  * Along with frequent abuses of excess whitespace
  * Anything inside parentheses or brackets were removed, as being potentially interruptive to otherwise cohesive phraseology
  * So also were run-on button smashes, like 'aaaaaaaaaaaaahhhh', reduced simply to 'ah'
  * Various common titles, like capt., mr., mrs., et cetera were normalized

--- 

## Method to the Madness



```{r simple plot, fig.height=3.5, fig.width=11, fig.align='center', message=F, eval=T, echo=F, warning=F }
require(ggplot2)
results <- readRDS("dat/test_results.rds")
resplot <- ggplot( results, aes(testbed, tally) )
respolt <- resplot + geom_bar

psf <- read.csv("data/psf_by_state.csv")
keep_these <- c('State','Date','MeanPrice')
do_not_melt <- c('RegionID','RegionName','SizeRank')
psf <- melt(psf, id.vars=do_not_melt, variable.name="Date", value.name="MeanPrice")
psf$Date <- as.Date( paste(psf$Date,'01'), 'X%Y.%m %d' )
colnames(psf)[2] <- 'State'
psf <- psf[,keep_these]
my_states <- subset(psf, State %in% c("District of Columbia","Virginia","Maine","Maryland"))
psf_plot <- ggplot(my_states, aes(Date, MeanPrice))
psf_plot <- psf_plot + geom_line(aes(color=State))
psf_plot <- psf_plot + xlab("") + ylab("Mean Price per Sq.Ft in Dollars")
psf_plot
```

Sadly, even as the jobs are being pulled into the cities, this one, at least, appears to be accelerating away from affordability.  The ratio in difference between the four in 2000 is significantly less acute than in 2015.

---

## A Quick Look across the Lower 48

![A Screenshot of Per-Square-Foot](assets/img/screenshot.png)

Thus, I introduce the first rudimentary version of the [Per Square Foot](https://jeturcotte.shinyapps.io/per-square-foot/) application which, for now, shows the mean square foot price for housing across most of the lower 48 states, both in the dollars of the time, and adjusted to the value of the 2016 dollar.

---

## Future Upgrades

* Would be nice to add similar breakdown by county, by zipcode, metro area, et cetera.
* Would be nice to offer a trend plot for the entire nation as a time series, and extrapolate into the future with predictions
* Would be nice to offer a trend plot, per state or other regionality, perhaps even in each popup, of the same information
* Would be nice to map out the mean price per square foot as a function of local cost of living and wages (affordability.)
* Would be nice to make similar chart based on rent instead of purchase cost.


